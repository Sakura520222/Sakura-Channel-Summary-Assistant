# Copyright 2026 Sakura-Bot
#
# æœ¬é¡¹ç›®é‡‡ç”¨ GNU Affero General Public License Version 3.0 (AGPL-3.0) è®¸å¯ï¼Œ
# å¹¶é™„åŠ éå•†ä¸šä½¿ç”¨é™åˆ¶æ¡æ¬¾ã€‚
#
# - ç½²åï¼šå¿…é¡»æä¾›æœ¬é¡¹ç›®çš„åŸå§‹æ¥æºé“¾æ¥
# - éå•†ä¸šï¼šç¦æ­¢ä»»ä½•å•†ä¸šç”¨é€”å’Œåˆ†å‘
# - ç›¸åŒæ–¹å¼å…±äº«ï¼šè¡ç”Ÿä½œå“å¿…é¡»é‡‡ç”¨ç›¸åŒçš„è®¸å¯è¯
#
# æœ¬é¡¹ç›®æºä»£ç ï¼šhttps://github.com/Sakura520222/Sakura-Bot
# è®¸å¯è¯å…¨æ–‡ï¼šå‚è§ LICENSE æ–‡ä»¶

"""
æ•°æ®åº“è¿ç§»å·¥å…·æ¨¡å—

æä¾›ä»SQLiteåˆ°MySQLçš„æ•°æ®åº“è¿ç§»åŠŸèƒ½ï¼Œé‡‡ç”¨æµå¼è¯»å–+åˆ†æ‰¹æ’å…¥ç­–ç•¥
"""

import json
import logging
import shutil
from datetime import UTC, datetime
from typing import Any

import aiofiles

from .database_mysql import MySQLManager
from .database_sqlite import SQLiteManager
from .i18n import get_text

logger = logging.getLogger(__name__)


class DatabaseMigrator:
    """æ•°æ®åº“è¿ç§»å™¨ï¼ˆSQLite -> MySQLï¼‰"""

    def __init__(self, sqlite_path: str = "data/summaries.db", mysql_config: dict = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¿ç§»å™¨

        Args:
            sqlite_path: SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„
            mysql_config: MySQLé…ç½®å­—å…¸
        """
        self.sqlite_path = sqlite_path
        self.mysql_config = mysql_config or {}
        self.sqlite_db = None
        self.mysql_db = None
        self.migration_status = {"status": "idle", "progress": 0, "message": "", "table_stats": {}}

    async def check_migration_ready(self) -> dict[str, Any]:
        """
        æ£€æŸ¥æ˜¯å¦å‡†å¤‡å¥½è¿›è¡Œè¿ç§»

        Returns:
            åŒ…å«æ£€æŸ¥ç»“æœçš„å­—å…¸
        """
        result = {
            "ready": False,
            "sqlite_exists": False,
            "mysql_configured": False,
            "mysql_connectable": False,
            "sqlite_tables": {},
            "message": "",
        }

        try:
            # æ£€æŸ¥SQLiteæ•°æ®åº“æ˜¯å¦å­˜åœ¨
            if await aiofiles.os.path.exists(self.sqlite_path):
                result["sqlite_exists"] = True

                # è¿æ¥SQLiteè·å–è¡¨ä¿¡æ¯
                self.sqlite_db = SQLiteManager(self.sqlite_path)
                # init_database() åœ¨æ„é€ å‡½æ•°ä¸­å·²è‡ªåŠ¨è°ƒç”¨

                # è·å–å„è¡¨çš„è®°å½•æ•°
                tables = [
                    "summaries",
                    "usage_quota",
                    "channel_profiles",
                    "conversation_history",
                    "users",
                    "subscriptions",
                    "request_queue",
                    "notification_queue",
                ]

                for table in tables:
                    try:
                        # SQLite ä½¿ç”¨åŒæ­¥è¿æ¥
                        conn = self.sqlite_db.get_connection()
                        cursor = conn.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        conn.close()
                        result["sqlite_tables"][table] = count
                    except Exception:
                        result["sqlite_tables"][table] = 0

            # æ£€æŸ¥MySQLé…ç½®
            if all(
                k in self.mysql_config for k in ["host", "port", "user", "password", "database"]
            ):
                result["mysql_configured"] = True

                # å°è¯•è¿æ¥MySQL
                try:
                    self.mysql_db = MySQLManager(**self.mysql_config)
                    await self.mysql_db.init_database()
                    result["mysql_connectable"] = True

                    # æ£€æŸ¥MySQLä¸­æ˜¯å¦å·²æœ‰æ•°æ®
                    stats = await self.mysql_db.get_statistics()
                    if stats.get("total_count", 0) > 0:
                        result["message"] = get_text("database.migrate.mysql_has_data")
                        result["ready"] = False
                    else:
                        result["ready"] = True
                        result["message"] = get_text("database.migrate.check_passed")

                except Exception as e:
                    result["message"] = (
                        f"{get_text('database.migrate.mysql_connect_error')}: {str(e)}"
                    )
                    logger.error(f"MySQLè¿æ¥æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)

            else:
                result["message"] = get_text("database.migrate.mysql_incomplete")

            return result

        except Exception as e:
            logger.error(f"è¿ç§»å‡†å¤‡æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
            result["message"] = f"{get_text('database.migrate.check_general_error')}: {str(e)}"
            return result

    async def migrate_data(self, chunk_size: int = 500) -> dict[str, Any]:
        """
        æ‰§è¡Œæ•°æ®è¿ç§»ï¼ˆé‡‡ç”¨æµå¼è¯»å–+åˆ†æ‰¹æ’å…¥ç­–ç•¥ï¼‰

        Args:
            chunk_size: æ¯æ‰¹å¤„ç†çš„æ•°æ®é‡

        Returns:
            è¿ç§»ç»“æœå­—å…¸
        """
        if not self.sqlite_db or not self.mysql_db:
            return {
                "success": False,
                "message": get_text("database.migrate.not_initialized"),
            }

        # å¤‡ä»½SQLiteæ•°æ®åº“
        backup_path = await self._backup_sqlite()
        if not backup_path:
            return {"success": False, "message": "SQLiteæ•°æ®åº“å¤‡ä»½å¤±è´¥"}

        self.migration_status = {
            "status": "in_progress",
            "progress": 0,
            "message": get_text("database.migrate.start_migrating"),
            "start_time": datetime.now(UTC).isoformat(),
            "table_stats": {},
        }

        try:
            # æŒ‰è¡¨è¿ç§»ï¼ˆè€ƒè™‘å¤–é”®ä¾èµ–å…³ç³»ï¼‰
            migration_order = [
                ("users", self._migrate_users),
                ("subscriptions", self._migrate_subscriptions),
                ("usage_quota", self._migrate_usage_quota),
                ("summaries", self._migrate_summaries),
                ("channel_profiles", self._migrate_channel_profiles),
                ("conversation_history", self._migrate_conversation_history),
                ("request_queue", self._migrate_request_queue),
                ("notification_queue", self._migrate_notification_queue),
            ]

            total_tables = len(migration_order)

            for idx, (table_name, migrate_func) in enumerate(migration_order):
                try:
                    logger.info(f"å¼€å§‹è¿ç§»è¡¨: {table_name}")
                    self.migration_status["message"] = (
                        f"{get_text('database.migrate.migrating_table')}: {table_name}"
                    )

                    stats = await migrate_func(chunk_size)
                    self.migration_status["table_stats"][table_name] = stats

                    progress = int((idx + 1) / total_tables * 100)
                    self.migration_status["progress"] = progress

                    logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆ: {stats}")

                except Exception as e:
                    logger.error(f"è¿ç§»è¡¨ {table_name} å¤±è´¥: {e}", exc_info=True)
                    raise

            self.migration_status["status"] = "completed"
            self.migration_status["message"] = get_text("database.migrate.migration_complete")
            self.migration_status["end_time"] = datetime.now(UTC).isoformat()

            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            verification = await self._verify_migration()

            # âš ï¸ ä¸åœ¨è¿ç§»è¿‡ç¨‹ä¸­åˆ é™¤ SQLite æ–‡ä»¶
            # åˆ é™¤æ“ä½œåº”åœ¨é‡å¯æˆåŠŸåã€éªŒè¯ MySQL å¯ç”¨åå†æ‰§è¡Œ
            logger.info("âœ… è¿ç§»å®Œæˆï¼Œä½†ä¿ç•™ SQLite æ–‡ä»¶ã€‚è¯·åœ¨é‡å¯å¹¶éªŒè¯ MySQL åæ‰‹åŠ¨åˆ é™¤ã€‚")

            return {
                "success": True,
                "message": get_text("database.migrate.migration_complete"),
                "stats": self.migration_status["table_stats"],
                "backup_path": backup_path,
                "verification": verification,
                "sqlite_deleted": False,  # è¿ç§»è¿‡ç¨‹ä¸­ä¸åˆ é™¤
                "sqlite_path": self.sqlite_path,  # è¿”å› SQLite è·¯å¾„ä¾›åç»­ä½¿ç”¨
            }

        except Exception as e:
            logger.error(f"è¿ç§»å¤±è´¥: {e}", exc_info=True)

            self.migration_status["status"] = "failed"
            self.migration_status["message"] = (
                f"{get_text('database.migrate.migration_failed')}: {str(e)}"
            )
            self.migration_status["end_time"] = datetime.now(UTC).isoformat()

            return {
                "success": False,
                "message": f"{get_text('database.migrate.migration_failed')}: {str(e)}",
                "backup_path": backup_path,
            }

    async def _backup_sqlite(self) -> str | None:
        """å¤‡ä»½SQLiteæ•°æ®åº“"""
        try:
            timestamp = datetime.now(UTC).strftime("%Y%m%d_%H%M%S")
            backup_path = f"{self.sqlite_path}.backup_{timestamp}"

            shutil.copy2(self.sqlite_path, backup_path)
            logger.info(f"SQLiteæ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
            return backup_path

        except Exception as e:
            logger.error(f"å¤‡ä»½SQLiteæ•°æ®åº“å¤±è´¥: {e}", exc_info=True)
            return None

    def _get_sqlite_data(self, query: str) -> list:
        """
        ä»SQLiteåŒæ­¥è¯»å–æ•°æ®ï¼ˆè¾…åŠ©æ–¹æ³•ï¼‰

        Args:
            query: SQLæŸ¥è¯¢è¯­å¥

        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        import sqlite3

        try:
            conn = sqlite3.connect(self.sqlite_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(query)
            rows = cursor.fetchall()
            conn.close()
            return rows
        except Exception as e:
            logger.error(f"SQLiteæŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            return []

    async def _migrate_users(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»ç”¨æˆ·è¡¨"""
        migrated = 0
        failed = 0

        try:
            # ä½¿ç”¨åŒæ­¥æ–¹å¼è¯»å– SQLite
            rows = self._get_sqlite_data("SELECT * FROM users")

            for row in rows:
                try:
                    # SQLite row: (user_id, username, first_name, registered_at, last_active, is_admin, preferences)
                    user_id = row[0]
                    username = row[1]
                    first_name = row[2]
                    is_admin = bool(row[5]) if len(row) > 5 else False

                    await self.mysql_db.register_user(
                        user_id=user_id,
                        username=username,
                        first_name=first_name,
                        is_admin=is_admin,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»ç”¨æˆ· {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»ç”¨æˆ·è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_subscriptions(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»è®¢é˜…è¡¨"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM subscriptions")

            for row in rows:
                try:
                    user_id = row[1]
                    channel_id = row[2]
                    channel_name = row[3] if len(row) > 3 else None
                    sub_type = row[4] if len(row) > 4 else "summary"

                    await self.mysql_db.add_subscription(
                        user_id=user_id,
                        channel_id=channel_id,
                        channel_name=channel_name,
                        sub_type=sub_type,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»è®¢é˜… {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»è®¢é˜…è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_usage_quota(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»é…é¢è¡¨"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM usage_quota")

            for row in rows:
                try:
                    user_id = row[1]
                    query_date = row[2]
                    usage_count = row[3]

                    # ç›´æ¥æ’å…¥MySQL
                    async with self.mysql_db.pool.acquire() as conn:
                        async with conn.cursor() as mysql_cursor:
                            await mysql_cursor.execute(
                                """
                                INSERT IGNORE INTO usage_quota
                                (user_id, query_date, usage_count)
                                VALUES (%s, %s, %s)
                            """,
                                (user_id, query_date, usage_count),
                            )
                            await conn.commit()
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»é…é¢è®°å½• {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»é…é¢è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_summaries(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»æ€»ç»“è¡¨ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM summaries")

            for row in rows:
                try:
                    # è§£ææ•°æ®
                    channel_id = row[1]
                    channel_name = row[2]
                    summary_text = row[3]
                    message_count = row[4]

                    # ğŸ”§ ä¿®å¤ï¼šå°† SQLite å­—ç¬¦ä¸²æ—¶é—´è½¬æ¢ä¸º datetime å¯¹è±¡
                    start_time_str = row[5] if len(row) > 5 else None
                    end_time_str = row[6] if len(row) > 6 else None

                    # è½¬æ¢æ—¶é—´å­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
                    from datetime import datetime

                    start_time = None
                    end_time = None

                    if start_time_str:
                        try:
                            # å°è¯•è§£æ ISO æ ¼å¼æ—¶é—´å­—ç¬¦ä¸²
                            if isinstance(start_time_str, str):
                                start_time = datetime.fromisoformat(
                                    start_time_str.replace("Z", "+00:00")
                                )
                            else:
                                start_time = start_time_str
                        except Exception as e:
                            logger.warning(f"è§£æ start_time å¤±è´¥: {start_time_str}, {e}")

                    if end_time_str:
                        try:
                            if isinstance(end_time_str, str):
                                end_time = datetime.fromisoformat(
                                    end_time_str.replace("Z", "+00:00")
                                )
                            else:
                                end_time = end_time_str
                        except Exception as e:
                            logger.warning(f"è§£æ end_time å¤±è´¥: {end_time_str}, {e}")

                    ai_model = row[8] if len(row) > 8 else "unknown"
                    summary_type = row[9] if len(row) > 9 else "weekly"

                    # è§£æJSONå­—æ®µ
                    summary_message_ids = None
                    if len(row) > 10 and row[10]:
                        try:
                            summary_message_ids = json.loads(row[10])
                        except Exception:
                            pass

                    poll_message_id = row[11] if len(row) > 11 else None
                    button_message_id = row[12] if len(row) > 12 else None

                    # æ’å…¥MySQL
                    new_id = await self.mysql_db.save_summary(
                        channel_id=channel_id,
                        channel_name=channel_name,
                        summary_text=summary_text,
                        message_count=message_count,
                        start_time=start_time,
                        end_time=end_time,
                        summary_message_ids=summary_message_ids,
                        poll_message_id=poll_message_id,
                        button_message_id=button_message_id,
                        ai_model=ai_model,
                        summary_type=summary_type,
                    )

                    if new_id:
                        migrated += 1
                    else:
                        failed += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»æ€»ç»“ {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»æ€»ç»“è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_channel_profiles(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»é¢‘é“ç”»åƒè¡¨"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM channel_profiles")

            for row in rows:
                try:
                    channel_id = row[0]
                    channel_name = row[1] if len(row) > 1 else None

                    await self.mysql_db.update_channel_profile(
                        channel_id=channel_id,
                        channel_name=channel_name,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»é¢‘é“ç”»åƒ {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»é¢‘é“ç”»åƒè¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_conversation_history(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»å¯¹è¯å†å²è¡¨ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM conversation_history")

            for row in rows:
                try:
                    user_id = row[1]
                    session_id = row[2]
                    role = row[3]
                    content = row[4]
                    metadata = None

                    if len(row) > 6 and row[6]:
                        try:
                            metadata = json.loads(row[6])
                        except Exception:
                            pass

                    await self.mysql_db.save_conversation(
                        user_id=user_id,
                        session_id=session_id,
                        role=role,
                        content=content,
                        metadata=metadata,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»å¯¹è¯è®°å½• {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»å¯¹è¯å†å²è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_request_queue(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»è¯·æ±‚é˜Ÿåˆ—è¡¨"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM request_queue")

            for row in rows:
                try:
                    request_type = row[1]
                    requested_by = row[2]
                    target_channel = row[3] if len(row) > 3 else None
                    params = None

                    if len(row) > 4 and row[4]:
                        try:
                            params = json.loads(row[4])
                        except Exception:
                            pass

                    await self.mysql_db.create_request(
                        request_type=request_type,
                        requested_by=requested_by,
                        target_channel=target_channel,
                        params=params,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»è¯·æ±‚ {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»è¯·æ±‚é˜Ÿåˆ—è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _migrate_notification_queue(self, chunk_size: int) -> dict[str, int]:
        """è¿ç§»é€šçŸ¥é˜Ÿåˆ—è¡¨"""
        migrated = 0
        failed = 0

        try:
            rows = self._get_sqlite_data("SELECT * FROM notification_queue")

            for row in rows:
                try:
                    user_id = row[1]
                    notification_type = row[2]
                    content = None

                    if len(row) > 3 and row[3]:
                        try:
                            content = json.loads(row[3])
                        except Exception:
                            pass

                    await self.mysql_db.create_notification(
                        user_id=user_id,
                        notification_type=notification_type,
                        content=content,
                    )
                    migrated += 1

                except Exception as e:
                    logger.warning(f"è¿ç§»é€šçŸ¥ {row[0]} å¤±è´¥: {e}")
                    failed += 1

        except Exception as e:
            logger.error(f"è¿ç§»é€šçŸ¥é˜Ÿåˆ—è¡¨å¤±è´¥: {e}", exc_info=True)

        return {"migrated": migrated, "failed": failed}

    async def _verify_migration(self) -> dict[str, Any]:
        """éªŒè¯è¿ç§»ç»“æœ"""
        try:
            sqlite_stats = {}
            mysql_stats = {}

            tables = [
                "users",
                "subscriptions",
                "usage_quota",
                "summaries",
                "channel_profiles",
                "conversation_history",
                "request_queue",
                "notification_queue",
            ]

            # è·å–SQLiteç»Ÿè®¡ï¼ˆåŒæ­¥æ–¹å¼ï¼‰
            for table in tables:
                try:
                    rows = self._get_sqlite_data(f"SELECT COUNT(*) FROM {table}")
                    sqlite_stats[table] = rows[0][0] if rows else 0
                except Exception:
                    sqlite_stats[table] = 0

            # è·å–MySQLç»Ÿè®¡
            async with self.mysql_db.pool.acquire() as conn:
                async with conn.cursor() as cursor:
                    for table in tables:
                        try:
                            await cursor.execute(f"SELECT COUNT(*) FROM {table}")
                            count = (await cursor.fetchone())[0]
                            mysql_stats[table] = count
                        except Exception:
                            mysql_stats[table] = 0

            # æ¯”è¾ƒç»“æœ
            verification = {
                "sqlite_stats": sqlite_stats,
                "mysql_stats": mysql_stats,
                "matched": True,
            }

            for table in tables:
                if sqlite_stats[table] != mysql_stats[table]:
                    verification["matched"] = False
                    logger.warning(
                        f"è¡¨ {table} æ•°æ®ä¸åŒ¹é…: SQLite={sqlite_stats[table]}, MySQL={mysql_stats[table]}"
                    )

            return verification

        except Exception as e:
            logger.error(f"éªŒè¯è¿ç§»å¤±è´¥: {e}", exc_info=True)
            return {"error": str(e)}

    def get_migration_status(self) -> dict[str, Any]:
        """è·å–è¿ç§»çŠ¶æ€"""
        return self.migration_status.copy()

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.sqlite_db:
            await self.sqlite_db.close()
        if self.mysql_db:
            await self.mysql_db.close()
