# Copyright 2026 Sakura-Bot
#
# æœ¬é¡¹ç›®é‡‡ç”¨ GNU Affero General Public License Version 3.0 (AGPL-3.0) è®¸å¯ï¼Œ
# å¹¶é™„åŠ éå•†ä¸šä½¿ç”¨é™åˆ¶æ¡æ¬¾ã€‚
#
# - ç½²åï¼šå¿…é¡»æä¾›æœ¬é¡¹ç›®çš„åŸå§‹æ¥æºé“¾æ¥
# - éå•†ä¸šï¼šç¦æ­¢ä»»ä½•å•†ä¸šç”¨é€”å’Œåˆ†å‘
# - ç›¸åŒæ–¹å¼å…±äº«ï¼šè¡ç”Ÿä½œå“å¿…é¡»é‡‡ç”¨ç›¸åŒçš„è®¸å¯è¯
#
# æœ¬é¡¹ç›®æºä»£ç ï¼šhttps://github.com/Sakura520222/Sakura-Bot
# è®¸å¯è¯å…¨æ–‡ï¼šå‚è§ LICENSE æ–‡ä»¶

"""
è‡ªç„¶è¯­è¨€æ„å›¾è§£æå™¨
ç†è§£ç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾
"""

import logging
import re
from typing import Any

logger = logging.getLogger(__name__)

# åœç”¨è¯åˆ—è¡¨ï¼ˆä¸ä½œä¸ºå…³é”®è¯æå–ï¼‰
STOPWORDS = {
    # ç–‘é—®/è¿æ¥è¯
    "ä»€ä¹ˆ",
    "ä»€ä¹ˆæ ·",
    "æ€ä¹ˆ",
    "æ€æ ·",
    "å¦‚ä½•",
    "ä¸ºä»€ä¹ˆ",
    "ä¸ºä½•",
    "å“ªé‡Œ",
    "å“ªä¸ª",
    "å“ªäº›",
    "æ˜¯å¦",
    "æœ‰æ²¡æœ‰",
    "æœ‰æ— ",
    "èƒ½å¦",
    "å¯ä»¥",
    "æ˜¯ä¸æ˜¯",
    # åŠ¨è¯
    "å‘ç”Ÿ",
    "å‘å¸ƒ",
    "æ›´æ–°",
    "è®¨è®º",
    "ä»‹ç»",
    "è®²",
    "è¯´",
    "çœ‹",
    "æŸ¥",
    "æ‰¾",
    "å¸®",
    "å‘Šè¯‰",
    "çŸ¥é“",
    "äº†è§£",
    "æŸ¥çœ‹",
    "åˆ†æ",
    "æ€»ç»“",
    "å›ç­”",
    "å›å¤",
    # ä»£è¯
    "æˆ‘",
    "ä½ ",
    "ä»–",
    "å¥¹",
    "å®ƒ",
    "æˆ‘ä»¬",
    "ä½ ä»¬",
    "ä»–ä»¬",
    "è¿™",
    "é‚£",
    "è¿™ä¸ª",
    "é‚£ä¸ª",
    "è¿™äº›",
    "é‚£äº›",
    "è¿™é‡Œ",
    "é‚£é‡Œ",
    # å‰¯è¯/ä»‹è¯/åŠ©è¯
    "æœ€è¿‘",
    "è¿‘æœŸ",
    "ä»Šå¤©",
    "æ˜¨å¤©",
    "å‰å¤©",
    "æœ¬å‘¨",
    "ä¸Šå‘¨",
    "è¿™å‘¨",
    "æœ¬æœˆ",
    "ä¸Šæœˆ",
    "è¿™æœˆ",
    "æœ€æ–°",
    "æ–°",
    "æ—§",
    "å¤§",
    "å°",
    "å¤š",
    "å°‘",
    "å¾ˆ",
    "éå¸¸",
    "æ¯”è¾ƒ",
    "ä¸€äº›",
    "ä¸€ä¸‹",
    "å…³äº",
    "æœ‰å…³",
    "çš„",
    "äº†",
    "å—",
    "å‘¢",
    "å•Š",
    "å§",
    "å—¯",
    "å’Œ",
    "ä¸",
    "æˆ–",
    "ä½†",
    "è€Œ",
    "æ‰€ä»¥",
    "å› æ­¤",
    "å› ä¸º",
    # é¢‘é“ç›¸å…³é€šç”¨è¯
    "é¢‘é“",
    "å†…å®¹",
    "ä¿¡æ¯",
    "æ¶ˆæ¯",
    "æ–°é—»",
    "èµ„è®¯",
    "åŠ¨æ€",
    "è®°å½•",
    "å†å²",
    "è¿‡å»",
    "æƒ…å†µ",
    "è¿›å±•",
}


class IntentParser:
    """æ„å›¾è§£æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ„å›¾è§£æå™¨"""
        # æ—¶é—´å…³é”®è¯æ˜ å°„ï¼šå…³é”®è¯ -> (å¤©æ•°åç§», æ˜¯å¦ç²¾ç¡®å½“å¤©)
        # å¤©æ•°è¡¨ç¤ºå¾€å‰å¤šå°‘å¤©ï¼ˆ0 = ä»Šå¤©ï¼‰
        self.time_keywords = {
            "ä»Šå¤©": 0,
            "ä»Šæ—¥": 0,
            "å½“å¤©": 0,
            "æ˜¨å¤©": 1,
            "æ˜¨æ—¥": 1,
            "å‰å¤©": 2,
            "å¤§å‰å¤©": 3,
            "æœ¬å‘¨": 7,
            "è¿™å‘¨": 7,
            "æœ¬æ˜ŸæœŸ": 7,
            "ä¸Šå‘¨": 14,
            "ä¸Šæ˜ŸæœŸ": 14,
            "è¿™ä¸ªæ˜ŸæœŸ": 7,
            "è¿™ä¸¤å¤©": 2,
            "è¿™å‡ å¤©": 3,
            "è¿™æ®µæ—¶é—´": 7,
            "è¿™æœˆ": 30,
            "æœ¬æœˆ": 30,
            "è¿™ä¸ªæœˆ": 30,
            "ä¸Šæœˆ": 60,
            "ä¸Šä¸ªæœˆ": 60,
            "æœ€è¿‘": 7,
            "è¿‘æœŸ": 7,
            "è¿‘æ¥": 7,
            "æœ€æ–°": 3,
            "æ–°è¿‘": 3,
            "ä»Šå¹´": 365,
            "ä»Šå¹´ä»¥æ¥": 365,
        }

    def parse_query(self, query: str) -> dict[str, Any]:
        """
        è§£æç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬

        Returns:
            {
                "intent": str,         # æ„å›¾ç±»å‹: summary, topic, keyword, stats, status
                "time_range": Optional[int],  # æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºä¸é™åˆ¶
                "keywords": List[str], # å…³é”®è¯
                "channel_id": Optional[str],  # é¢‘é“ID
                "original_query": str, # åŸå§‹æŸ¥è¯¢
                "confidence": float    # ç½®ä¿¡åº¦
            }
        """
        query = query.strip()
        logger.info(f"è§£ææŸ¥è¯¢: {query}")

        result = {
            "original_query": query,
            "intent": "summary",
            "time_range": None,
            "keywords": [],
            "channel_id": None,
            "confidence": 0.0,
        }

        # 1. æ£€æµ‹çŠ¶æ€æŸ¥è¯¢æ„å›¾
        if self._is_status_query(query):
            result["intent"] = "status"
            result["confidence"] = 0.9
            logger.info("è¯†åˆ«ä¸ºçŠ¶æ€æŸ¥è¯¢æ„å›¾")
            return result

        # 2. æ£€æµ‹ç»Ÿè®¡æŸ¥è¯¢æ„å›¾
        if self._is_stats_query(query):
            result["intent"] = "stats"
            result["confidence"] = 0.9
            logger.info("è¯†åˆ«ä¸ºç»Ÿè®¡æŸ¥è¯¢æ„å›¾")
            return result

        # 3. æå–æ—¶é—´èŒƒå›´
        time_range = self._extract_time_range(query)
        if time_range is not None:
            result["time_range"] = time_range
            logger.info(f"æå–æ—¶é—´èŒƒå›´: {time_range}å¤©")

        # 4. æå–å…³é”®è¯ï¼ˆæ™ºèƒ½æå–ï¼Œä¸ä¾èµ–ç¡¬ç¼–ç è¯å…¸ï¼‰
        keywords = self._extract_keywords(query)
        if keywords:
            result["keywords"] = keywords
            result["intent"] = "keyword"
            logger.info(f"æå–å…³é”®è¯: {keywords}")

        # 5. æ£€æµ‹ä¸»é¢˜æŸ¥è¯¢ï¼ˆä¸»é¢˜ä¼šè¿½åŠ åˆ°å…³é”®è¯ä¸­ï¼‰
        topics = self._extract_topics(query)
        if topics:
            # åªæ·»åŠ ä¸åœ¨å·²æœ‰å…³é”®è¯ä¸­çš„ä¸»é¢˜è¯
            for t in topics:
                if t not in result["keywords"]:
                    result["keywords"].append(t)
            if result["intent"] == "summary":
                result["intent"] = "topic"
            logger.info(f"æå–ä¸»é¢˜: {topics}")

        # 6. è®¡ç®—ç½®ä¿¡åº¦
        if time_range is not None or result["keywords"]:
            result["confidence"] = 0.8
        else:
            result["confidence"] = 0.5
            result["intent"] = "summary"
            # æ²¡æœ‰æ—¶é—´çº¦æŸæ—¶ä¸é»˜è®¤é™åˆ¶7å¤©ï¼Œè®©å‘é‡æ£€ç´¢å†³å®š
            # result["time_range"] ä¿æŒ None

        return result

    def _is_status_query(self, query: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçŠ¶æ€æŸ¥è¯¢"""
        status_keywords = [
            "é…é¢",
            "å‰©ä½™",
            "è¿˜èƒ½",
            "å‡ æ¬¡",
            "é™é¢",
            "quota",
            "remaining",
            "limit",
            "æ¬¡æ•°",
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in status_keywords)

    def _is_stats_query(self, query: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç»Ÿè®¡æŸ¥è¯¢"""
        stats_keywords = [
            "ç»Ÿè®¡",
            "æ€»æ•°",
            "å¤šå°‘æ¡",
            "æœ‰å¤šå°‘æ¡",
            "æ•°é‡",
            "æ’å",
            "æ’è¡Œ",
            "top",
            "æ€»å…±æœ‰å¤šå°‘",
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in stats_keywords)

    def _extract_time_range(self, query: str) -> int | None:
        """
        æå–æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰

        æ”¯æŒçš„æ¨¡å¼ï¼š
        - ä»Šå¤©/æ˜¨å¤©/å‰å¤© ç­‰å…³é”®è¯
        - æœ€è¿‘Nå¤©/Næ—¥/Nå‘¨/Nä¸ªæœˆ ç­‰æ•°é‡è¡¨è¾¾
        - è¿‡å»Nå¤© ç­‰è¡¨è¾¾
        """
        # 1. ç²¾ç¡®æ•°å­—+å•ä½æ¨¡å¼ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        # "æœ€è¿‘3å¤©" / "è¿‡å»7å¤©" / "æœ€è¿‘3æ—¥"
        match = re.search(r"(?:æœ€è¿‘|è¿‡å»|è¿‘|å‰)\s*(\d+)\s*[å¤©æ—¥]", query)
        if match:
            return int(match.group(1))

        # "æœ€è¿‘Nå‘¨"
        match = re.search(r"(?:æœ€è¿‘|è¿‡å»|è¿‘|å‰)\s*(\d+)\s*å‘¨", query)
        if match:
            return int(match.group(1)) * 7

        # "æœ€è¿‘Nä¸ªæœˆ" / "æœ€è¿‘Næœˆ"
        match = re.search(r"(?:æœ€è¿‘|è¿‡å»|è¿‘|å‰)\s*(\d+)\s*(?:ä¸ªæœˆ|æœˆ)", query)
        if match:
            return int(match.group(1)) * 30

        # è£¸æ•°å­—+å¤©ï¼ˆå¦‚"7å¤©"ã€"30æ—¥"ï¼‰
        match = re.search(r"(\d+)\s*[å¤©æ—¥]", query)
        if match:
            days = int(match.group(1))
            if 1 <= days <= 365:  # åˆç†èŒƒå›´å†…
                return days

        # 2. å…³é”®è¯åŒ¹é…ï¼ˆæŒ‰å…³é”®è¯é•¿åº¦é™åºï¼Œä¼˜å…ˆåŒ¹é…é•¿è¯ï¼‰
        sorted_keywords = sorted(self.time_keywords.keys(), key=len, reverse=True)
        for keyword in sorted_keywords:
            if keyword in query:
                return self.time_keywords[keyword]

        return None

    def _extract_keywords(self, query: str) -> list[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯

        ç­–ç•¥ï¼š
        1. ç§»é™¤æ—¶é—´è¯ã€åœç”¨è¯ç­‰æ— æ„ä¹‰è¯æ±‡
        2. æå–é•¿åº¦ >= 2 çš„ä¸­æ–‡è¯æ®µå’Œè‹±æ–‡è¯
        3. è¿”å›æœ€å¤š 5 ä¸ªå…³é”®è¯
        """
        # ç§»é™¤æ—¶é—´å…³é”®è¯ï¼ˆé¿å…æ—¶é—´è¯æˆä¸ºå…³é”®è¯ï¼‰
        filtered = query
        for keyword in self.time_keywords.keys():
            filtered = filtered.replace(keyword, " ")

        # ç§»é™¤ç–‘é—®å¥å°¾ï¼ˆ"å—"ã€"å‘¢"ã€"ï¼Ÿ"ç­‰ï¼‰
        filtered = re.sub(r"[ï¼Ÿ?ï¼!ã€‚ï¼Œ,ã€ï¼›;ï¼š:]", " ", filtered)

        keywords = []

        # æå–è‹±æ–‡è¯ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼Œé•¿åº¦>=2ï¼‰
        eng_words = re.findall(r"[A-Za-z][A-Za-z0-9\-_.]{1,}", filtered)
        for w in eng_words:
            if w.lower() not in STOPWORDS and w not in keywords:
                keywords.append(w)

        # æå–ä¸­æ–‡è¯æ®µï¼šä½¿ç”¨æ­£åˆ™åˆ†å‰²åè¿‡æ»¤åœç”¨è¯
        # æŒ‰ç©ºæ ¼/æ ‡ç‚¹åˆ†å‰²ï¼Œä¿ç•™é•¿åº¦>=2çš„ä¸­æ–‡è¯ç»„
        segments = re.split(r"[\s\u0000-\u00ff]+", filtered)
        for seg in segments:
            # åªå¤„ç†ä¸­æ–‡å­—ç¬¦ç»„æˆçš„è¯æ®µï¼ˆå«ä¸­æ–‡çš„ç‰‡æ®µï¼‰
            if len(seg) >= 2 and re.search(r"[\u4e00-\u9fff]", seg):
                # å°è¯•æå–å­è¯æ®µï¼ˆ2-8å­—ç¬¦çš„è¿ç»­ä¸­æ–‡ç‰‡æ®µï¼‰
                cn_words = re.findall(r"[\u4e00-\u9fff]{2,8}", seg)
                for w in cn_words:
                    if w not in STOPWORDS and w not in keywords:
                        keywords.append(w)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        seen = set()
        unique_kw = []
        for kw in keywords:
            lower = kw.lower()
            if lower not in seen:
                seen.add(lower)
                unique_kw.append(kw)

        return unique_kw[:6]

    def _extract_topics(self, query: str) -> list[str]:
        """æå–ä¸»é¢˜ï¼ˆåŸºäºè¯­ä¹‰æ¨¡å¼ï¼‰"""
        topics = []

        topic_patterns = {
            "æŠ€æœ¯": [
                r"æŠ€æœ¯",
                r"å¼€å‘",
                r"ç¼–ç¨‹",
                r"ä»£ç ",
                r"å·¥ç¨‹",
                r"ç®—æ³•",
                r"æ¡†æ¶",
                r"æ¥å£",
                r"API",
            ],
            "æ–°é—»": [r"æ–°é—»", r"èµ„è®¯", r"æ¶ˆæ¯", r"å…¬å‘Š", r"é€šçŸ¥", r"å‘å¸ƒ", r"å£°æ˜"],
            "è®¨è®º": [r"è®¨è®º", r"çœ‹æ³•", r"è§‚ç‚¹", r"è¯„è®º", r"æ„è§", r"åˆ†æ", r"è¯„ä»·"],
            "æ›´æ–°": [r"æ›´æ–°", r"å‡çº§", r"æ–°ç‰ˆæœ¬", r"ç‰ˆæœ¬", r"æ”¹è¿›", r"è¿­ä»£", r"å‘å¸ƒ"],
            "é—®é¢˜": [r"é—®é¢˜", r"bug", r"é”™è¯¯", r"æ•…éšœ", r"å¼‚å¸¸", r"æŠ¥é”™", r"å¤±è´¥"],
            "å¸‚åœº": [r"å¸‚åœº", r"ä»·æ ¼", r"è¡Œæƒ…", r"æ¶¨", r"è·Œ", r"äº¤æ˜“", r"æŠ•èµ„"],
            "AI": [r"AI", r"äººå·¥æ™ºèƒ½", r"æ¨¡å‹", r"å¤§æ¨¡å‹", r"GPT", r"LLM", r"æœºå™¨å­¦ä¹ "],
        }

        query_lower = query.lower()
        for topic, patterns in topic_patterns.items():
            if any(re.search(p, query_lower, re.IGNORECASE) for p in patterns):
                topics.append(topic)

        return topics

    def format_query_result(self, parsed: dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–è§£æç»“æœï¼ˆç”¨äºè°ƒè¯•ï¼‰
        """
        intent_map = {
            "summary": "æ€»ç»“æŸ¥è¯¢",
            "keyword": "å…³é”®è¯æŸ¥è¯¢",
            "topic": "ä¸»é¢˜æŸ¥è¯¢",
            "stats": "ç»Ÿè®¡æŸ¥è¯¢",
            "status": "çŠ¶æ€æŸ¥è¯¢",
        }

        result = "ğŸ” æŸ¥è¯¢è§£æ:\n"
        result += f"æ„å›¾: {intent_map.get(parsed['intent'], parsed['intent'])}\n"

        if parsed.get("time_range") is not None:
            result += f"æ—¶é—´èŒƒå›´: æœ€è¿‘{parsed['time_range']}å¤©\n"
        else:
            result += "æ—¶é—´èŒƒå›´: ä¸é™\n"

        if parsed.get("keywords"):
            result += f"å…³é”®è¯: {', '.join(parsed['keywords'])}\n"

        result += f"ç½®ä¿¡åº¦: {parsed['confidence']:.0%}\n"

        return result


# åˆ›å»ºå…¨å±€æ„å›¾è§£æå™¨å®ä¾‹
intent_parser = None


def get_intent_parser():
    """è·å–å…¨å±€æ„å›¾è§£æå™¨å®ä¾‹"""
    global intent_parser
    if intent_parser is None:
        intent_parser = IntentParser()
    return intent_parser
